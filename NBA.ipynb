{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TonyLiu836/NBA-MVP-Predictor/blob/NN/NBA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H3RwcE2VVFHE"
   },
   "outputs": [],
   "source": [
    "!pip install nba_api\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyYA6FzBZN5L"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8svVwDvo0ei"
   },
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPPdindE3cTK"
   },
   "source": [
    "### Get player stats by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "20e1Ka7Eo0ek",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import teamplayerdashboard\n",
    "from nba_api.stats.endpoints import leaguedashteamstats\n",
    "from nba_api.stats.endpoints import playerdashboardbyyearoveryear\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Get list of teams that played in a season\n",
    "def get_teams(start_year):\n",
    "    end_year = (start_year + 1) % 100\n",
    "    leagueteams = leaguedashteamstats.LeagueDashTeamStats(season=f'{start_year}-{end_year:02}')\n",
    "    teams = leagueteams.get_data_frames()[0]\n",
    "    return teams.loc[:, 'TEAM_ID']\n",
    "\n",
    "# Get list of players that played > 1000 min and scored > 600 points for a team in a season.\n",
    "# 1000 min and 600 points total is ~12 mpg and 7 ppg so this filters out players that don't get much playtime.\n",
    "def get_players(team_id, start_year):\n",
    "    end_year = (start_year + 1) % 100\n",
    "    teamplayers = teamplayerdashboard.TeamPlayerDashboard(team_id, season=f'{start_year}-{end_year:02}')\n",
    "    players = teamplayers.get_data_frames()[1]\n",
    "    good_players = players[players.loc[:,'MIN'] > 1000]\n",
    "    good_players = good_players[good_players.loc[:, 'PTS'] > 600]\n",
    "    return good_players.loc[:, ['PLAYER_ID', 'PLAYER_NAME']]\n",
    "\n",
    "# Get player stats for a season\n",
    "def get_player_stats(player_id, start_year):\n",
    "    end_year = (start_year + 1) % 100\n",
    "    playerdashboard = playerdashboardbyyearoveryear.PlayerDashboardByYearOverYear(player_id, per_mode_detailed='PerGame')\n",
    "    stats = playerdashboard.get_data_frames()[1]\n",
    "    seasonstats = stats[stats['GROUP_VALUE'] == f'{start_year}-{end_year:02}']\n",
    "    return seasonstats.drop(columns=['GROUP_SET', 'TEAM_ID', 'MAX_GAME_DATE', 'CFID', 'CFPARAMS'])\n",
    "\n",
    "teams_2020 = get_teams(2020)\n",
    "rand_team = get_players(teams_2020.iat[random.randint(0, 29)], 2020)\n",
    "print(rand_team.shape)\n",
    "rand_player = rand_team.iloc[random.randint(0, 5), :]\n",
    "print(rand_player)\n",
    "stats = get_player_stats(rand_player.iat[0], 2020)\n",
    "print(stats)\n",
    "print(stats.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KQJ2xlHRo0em",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from nba_api.stats.endpoints import teamplayerdashboard\n",
    "from nba_api.stats.endpoints import leaguedashteamstats\n",
    "\n",
    "# Iterate through each season and save data to csv\n",
    "for start_year in range(2012, 2022):\n",
    "    data = []\n",
    "    end_year = (start_year + 1) % 100\n",
    "    print(f'{start_year}-{end_year:02}')\n",
    "    leagueteams = get_teams(start_year)\n",
    "    for team_id in leagueteams:\n",
    "        players = get_players(team_id, start_year)\n",
    "        for player in players.itertuples():\n",
    "            print(player)\n",
    "            time.sleep(1)\n",
    "            stats = get_player_stats(player[1], start_year)\n",
    "            stats.insert(0, \"PLAYER_NAME\", player[2])\n",
    "            data.append(stats)\n",
    "    \n",
    "    big_data = pd.concat(data)\n",
    "    big_data.to_csv(f'{start_year}-{end_year:02}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0T7JpNP3cTS"
   },
   "source": [
    "### Get MVP List, MVP Votes, ROY Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UUuLPPkOo0er"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "URL = \"https://www.nba.com/news/history-mvp-award-winners\"\n",
    "page = requests.get(URL)\n",
    "\n",
    "#webscrape NBA.com's mvp page for MVP names and corresponding years\n",
    "def get_MVP_List():\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(id = \"__next\")\n",
    "    players = results.find_all(\"div\", class_=\"Article_article__2Ue3h\")\n",
    "    rawData = []\n",
    "    for sample in players:\n",
    "      mvps = sample.find_all(\"p\")\n",
    "      for mvp in mvps:\n",
    "        rawData.append(str(mvp))\n",
    "\n",
    "    rawData = rawData[2:]\n",
    "    mvp_list = []\n",
    "    for j in rawData:\n",
    "      j = j[3:]                   #get rid of <p> and </p>\n",
    "      j = j[:-4]\n",
    "      info = j.split()  \n",
    "      mvp_list.append([info[0], info[2] + \" \" + info[3], info[4] + \" \" + info[5]])\n",
    "\n",
    "    return mvp_list\n",
    "\n",
    "mvp_data = get_MVP_List()\n",
    "\n",
    "mvp_dataframe = pd.DataFrame(mvp_data, columns = [\"season\", \"Name\", \"Team\"])\n",
    "mvp_dataframe.to_csv(\"data/MVP_List.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 405
    },
    "collapsed": true,
    "id": "aRaYRxUY-xcv",
    "outputId": "dc519b62-0d5f-49fe-93ad-d9f955e6e7b5"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-201db4b969d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/data/data\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'google.colab'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmvp_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{data_dir}/MVP_List.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmvp_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmvp_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"season\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m\"1996-97\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mseasons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"season\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/data/data/MVP_List.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import time, requests\n",
    "\n",
    "data_dir = \"/home/data/data\" if 'google.colab' in str(get_ipython()) else \"data\"\n",
    "mvp_list = pd.read_csv(f'{data_dir}/MVP_List.csv')\n",
    "samples = mvp_list.loc[mvp_list[\"season\"] >= \"1996-97\"]\n",
    "seasons = samples[\"season\"]\n",
    "seasons = [season[0:4] for season in seasons]\n",
    "\n",
    "def getAwardVotes(seasons):\n",
    "    award_names = [\"mvp\", \"roy\"]\n",
    "    table_data = []\n",
    "    for season in seasons:\n",
    "        year = int(season) + 1\n",
    "        print(year)\n",
    "        time.sleep(1)\n",
    "        URL = \"https://www.basketball-reference.com/awards/awards_\" + str(year) + \".html\"\n",
    "        page = requests.get(URL)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        for award in award_names:\n",
    "            print(award)\n",
    "            tables = soup.find(\"table\", id = award)\n",
    "            stats = tables.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "            for row in stats:\n",
    "                player_name = row.find(\"td\", {\"data-stat\":\"player\"}).find(\"a\").get_text()\n",
    "                first_votes = row.find(\"td\", {\"data-stat\":\"votes_first\"}).get_text()\n",
    "                pts_won = row.find(\"td\", {\"data-stat\":\"points_won\"}).get_text()\n",
    "                pts_max = row.find(\"td\", {\"data-stat\":\"points_max\"}).get_text()\n",
    "                award_share = row.find(\"td\", {\"data-stat\":\"award_share\"}).get_text()\n",
    "                table_data.append([season + \"-\" + str(year)[-2:], award,player_name, first_votes,pts_won, pts_max, award_share])\n",
    "    return table_data\n",
    "\n",
    "awards_data = getAwardVotes(seasons)\n",
    "awards_dataframe = pd.DataFrame(awards_data, columns = [\"season\",\"Award\", \"Name\", \"First Votes\", \"Points Won\", \"Max Points\", \"Award Shares\"])\n",
    "awards_dataframe.to_csv(\"data/Awards_Voting_Data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Rxqd4EAw0JF",
    "outputId": "a7d04c80-2051-4563-ffc1-9f1506d1c38c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at drive\n",
      "/content/drive/MyDrive/NBA_MLProject\n",
      "/content/drive/MyDrive/NBA_MLProject\n",
      "Archive:  data.zip\n",
      "   creating: /home/data/data/\n",
      "  inflating: /home/data/data/1996-97.csv  \n",
      "  inflating: /home/data/data/1997-98.csv  \n",
      "  inflating: /home/data/data/1998-99.csv  \n",
      "  inflating: /home/data/data/1999-00.csv  \n",
      "  inflating: /home/data/data/2000-01.csv  \n",
      "  inflating: /home/data/data/2001-02.csv  \n",
      "  inflating: /home/data/data/2002-03.csv  \n",
      "  inflating: /home/data/data/2003-04.csv  \n",
      "  inflating: /home/data/data/2004-05.csv  \n",
      "  inflating: /home/data/data/2005-06.csv  \n",
      "  inflating: /home/data/data/2006-07.csv  \n",
      "  inflating: /home/data/data/2007-08.csv  \n",
      "  inflating: /home/data/data/2008-09.csv  \n",
      "  inflating: /home/data/data/2009-10.csv  \n",
      "  inflating: /home/data/data/2010-11.csv  \n",
      "  inflating: /home/data/data/2011-12.csv  \n",
      "  inflating: /home/data/data/2012-13.csv  \n",
      "  inflating: /home/data/data/2013-14.csv  \n",
      "  inflating: /home/data/data/2014-15.csv  \n",
      "  inflating: /home/data/data/2015-16.csv  \n",
      "  inflating: /home/data/data/2016-17.csv  \n",
      "  inflating: /home/data/data/2017-18.csv  \n",
      "  inflating: /home/data/data/2018-19.csv  \n",
      "  inflating: /home/data/data/2019-20.csv  \n",
      "  inflating: /home/data/data/2020-21.csv  \n",
      "  inflating: /home/data/data/2021-22.csv  \n",
      "  inflating: /home/data/data/MVP_List.csv  \n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('drive')\n",
    "%cd /content/drive/MyDrive/NBA_MLProject\n",
    "!pwd\n",
    "!unzip data.zip -d /home/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CZRe81bQNmOs"
   },
   "outputs": [],
   "source": [
    "!cp Awards_Voting_Data.csv -d /home/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nF38wJnY3gnu"
   },
   "source": [
    "#### Split years using K-fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "s7HGITML3qcC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 5\n",
    "data_dir = \"/home/data/data\" if 'google.colab' in str(get_ipython()) else \"data\"\n",
    "def splitDataYears():\n",
    "    '''\n",
    "    Splits available seasons into folds, with each fold containing a list of seasons in random order\n",
    "    Outputs: (trainingFolds, testData)\n",
    "        trainingFolds = [ [[training seasons], [validation seasons]] * num_folds ]\n",
    "        testData = [testing seasons]\n",
    "    '''\n",
    "    mvp_list = pd.read_csv(f'{data_dir}/MVP_List.csv')\n",
    "    samples = mvp_list.loc[mvp_list[\"season\"] >= \"1996-97\"]\n",
    "    years = samples[\"season\"]\n",
    "    trainingSamples = years.sample(frac=0.8)    #80/20 split for training/testing data \n",
    "    testSamples = years.drop(trainingSamples.index)\n",
    "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=None)   #split training data into 5 folds, each fold contains 4 seasons\n",
    "\n",
    "    trainingFolds = []\n",
    "    for train, valid in kf.split(trainingSamples):\n",
    "      trainingFolds.append([trainingSamples.iloc[train].values.tolist(), trainingSamples.iloc[valid].values.tolist()])\n",
    "      \n",
    "    testData = []\n",
    "    for i in range(testSamples.size):\n",
    "      testData.append(testSamples.iloc[i])\n",
    "    return trainingFolds, testData\n",
    "\n",
    "trainingSet, testingSet = splitDataYears()\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AEjCMWUI8_N0",
    "outputId": "d5619e91-4390-494d-e71b-e42f97954d2d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         PLAYER_NAME GROUP_VALUE  GP   W   L  W_PCT   MIN  FGM   FGA  FG_PCT  \\\n",
      "0      Al Harrington     2005-06  76  24  52  0.316  36.6  7.3  16.1   0.452   \n",
      "1        Joe Johnson     2005-06  82  26  56  0.317  40.7  7.7  17.0   0.453   \n",
      "2     Josh Childress     2005-06  74  24  50  0.324  30.4  3.8   6.8   0.552   \n",
      "3         Josh Smith     2005-06  80  26  54  0.325  32.0  4.1   9.7   0.425   \n",
      "4    Marvin Williams     2005-06  79  25  54  0.316  24.7  3.0   6.7   0.443   \n",
      "..               ...         ...  ..  ..  ..    ...   ...  ...   ...     ...   \n",
      "157      Mehmet Okur     2005-06  82  41  41  0.500  35.9  6.3  13.8   0.460   \n",
      "158   Antawn Jamison     2005-06  82  42  40  0.512  40.1  8.0  18.2   0.442   \n",
      "159  Antonio Daniels     2005-06  80  42  38  0.525  28.5  2.9   6.9   0.418   \n",
      "160     Caron Butler     2005-06  75  40  35  0.533  36.1  6.6  14.5   0.455   \n",
      "161   Gilbert Arenas     2005-06  80  40  40  0.500  42.3  9.3  20.9   0.447   \n",
      "\n",
      "     ...  AST  TOV  STL  BLK  BLKA   PF   PTS  PLUS_MINUS  DD2  TD3  \n",
      "0    ...  3.1  2.6  1.1  0.2   0.9  4.0  18.6        -4.4   15    0  \n",
      "1    ...  6.5  3.3  1.3  0.4   0.5  2.3  20.2        -4.6   13    1  \n",
      "2    ...  1.8  1.4  1.2  0.5   0.7  2.5  10.0        -2.5    6    0  \n",
      "3    ...  2.4  2.0  0.8  2.6   0.4  3.3  11.3        -4.0   11    0  \n",
      "4    ...  0.8  1.1  0.6  0.3   0.7  2.9   8.5        -1.1    4    0  \n",
      "..   ...  ...  ...  ...  ...   ...  ...   ...         ...  ...  ...  \n",
      "157  ...  2.4  2.0  0.5  0.9   0.8  3.5  18.0        -1.4   35    0  \n",
      "158  ...  1.9  1.7  1.1  0.1   0.7  2.3  20.5         3.0   35    0  \n",
      "159  ...  3.6  1.1  0.7  0.1   0.3  1.2   9.6         1.5    0    0  \n",
      "160  ...  2.5  2.3  1.7  0.2   0.8  3.2  17.6         1.6   10    0  \n",
      "161  ...  6.1  3.7  2.0  0.3   0.8  3.6  29.3         2.6    9    0  \n",
      "\n",
      "[149 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_dir = \"/home/data/data\" if 'google.colab' in str(get_ipython()) else \"data\"\n",
    "\n",
    "drop_cols = ['Unnamed: 0', 'TEAM_ABBREVIATION', 'PFD', 'NBA_FANTASY_PTS',\n",
    "                'GP_RANK', 'W_RANK', 'L_RANK', 'W_PCT_RANK', 'MIN_RANK',\n",
    "                'FGM_RANK', 'FGA_RANK', 'FG_PCT_RANK', 'FG3M_RANK', 'FG3A_RANK', 'FG3_PCT_RANK', \n",
    "                'FTM_RANK', 'FTA_RANK', 'FT_PCT_RANK', 'OREB_RANK', 'DREB_RANK', 'REB_RANK',\n",
    "                'AST_RANK', 'TOV_RANK', 'STL_RANK', 'BLK_RANK', 'BLKA_RANK', 'PF_RANK', 'PFD_RANK',\n",
    "                'PTS_RANK', 'PLUS_MINUS_RANK', 'NBA_FANTASY_PTS_RANK', 'DD2_RANK', 'TD3_RANK']\n",
    "\n",
    "mvp_rename_cols = {\"Name\": \"PLAYER_NAME\", \"season\": \"GROUP_VALUE\", \"Award Shares\": \"MVP_SHARES\"}\n",
    "roy_rename_cols = {\"Name\": \"PLAYER_NAME\", \"season\": \"GROUP_VALUE\", \"Award Shares\": \"ROY_SHARES\"}\n",
    "\n",
    "vote_data = pd.read_csv(f\"{data_dir}/Awards_Voting_Data.csv\")\n",
    "\n",
    "# separate vote_data by award, rename cols to match player data\n",
    "mvp_vote_data = vote_data.loc[vote_data['Award'] == \"mvp\"]\n",
    "mvp_vote_data = mvp_vote_data.rename(columns=mvp_rename_cols)\n",
    "\n",
    "roy_vote_data = vote_data.loc[vote_data[\"Award\"] == \"roy\"]\n",
    "roy_vote_data = roy_vote_data.rename(columns=roy_rename_cols)\n",
    "\n",
    "# form train, val, test data sets\n",
    "# drop duplicates removes individual team entries but keeps season totals if player plays for more than one team in a season\n",
    "train = [[pd.read_csv(f\"{data_dir}/{season}.csv\").drop(columns=drop_cols).drop_duplicates(subset=['PLAYER_NAME'])\n",
    "         for season in trainingSet[k][0]] for k in range(num_folds)]\n",
    "\n",
    "val = [[pd.read_csv(f\"{data_dir}/{season}.csv\").drop(columns=drop_cols).drop_duplicates(subset=['PLAYER_NAME'])\n",
    "         for season in trainingSet[k][1]] for k in range(num_folds)]\n",
    "\n",
    "test = [pd.read_csv(f\"{data_dir}/{season}.csv\").drop(columns=drop_cols).drop_duplicates(subset=['PLAYER_NAME'])\n",
    "         for season in testingSet]\n",
    "\n",
    "print(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for NaNs\n",
    "for fold in train:\n",
    "    for season in fold:\n",
    "        if season.isnull().values.any():\n",
    "            print(\"train:\", season)\n",
    "for fold in val:\n",
    "    for season in fold:\n",
    "        if season.isnull().values.any():\n",
    "            print(\"val:\", season)\n",
    "for season in test:\n",
    "    if season.isnull().values.any():\n",
    "        print(\"test:\", season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQAr-r12q6RR"
   },
   "source": [
    "#### Add award shares data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "axA4Hhkoq6RT"
   },
   "outputs": [],
   "source": [
    "assert(\"MVP_SHARES\" not in train[0][0]), \"MVP_SHARES already added to df\"\n",
    "mvp = mvp_vote_data.loc[:,[\"PLAYER_NAME\", \"GROUP_VALUE\", \"MVP_SHARES\"]]\n",
    "\n",
    "for i in range(len(train)):\n",
    "    for j in range(len(train[i])):\n",
    "        train[i][j] = train[i][j].merge(mvp, how='left', on=[\"PLAYER_NAME\", \"GROUP_VALUE\"])   #union of both dataframes, if no vote shares value found then set to Nan\n",
    "        train[i][j].fillna(value={\"MVP_SHARES\": 0.}, inplace=True)                             # replace Nans with 0\n",
    "\n",
    "for i in range(len(val)):\n",
    "    for j in range(len(val[i])):\n",
    "        val[i][j] = val[i][j].merge(mvp, how='left', on=[\"PLAYER_NAME\", \"GROUP_VALUE\"])\n",
    "        val[i][j].fillna(value={\"MVP_SHARES\": 0.}, inplace=True)\n",
    "                \n",
    "for i in range(len(test)):\n",
    "    test[i] = test[i].merge(mvp, how='left', on=[\"PLAYER_NAME\", \"GROUP_VALUE\"])\n",
    "    test[i].fillna(value={\"MVP_SHARES\": 0.}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "t35I9BaPq6RW",
    "outputId": "1a4cddbc-7611-4e5f-aae6-396cda5448da"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PLAYER_NAME</th>\n",
       "      <th>GROUP_VALUE</th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W_PCT</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>...</th>\n",
       "      <th>TOV</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>BLKA</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "      <th>MVP_SHARES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>79</td>\n",
       "      <td>47</td>\n",
       "      <td>32</td>\n",
       "      <td>0.595</td>\n",
       "      <td>42.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.480</td>\n",
       "      <td>...</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>31.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>81</td>\n",
       "      <td>60</td>\n",
       "      <td>21</td>\n",
       "      <td>0.741</td>\n",
       "      <td>38.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.480</td>\n",
       "      <td>...</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Chauncey Billups</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>17</td>\n",
       "      <td>0.790</td>\n",
       "      <td>36.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.418</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Elton Brand</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>79</td>\n",
       "      <td>44</td>\n",
       "      <td>35</td>\n",
       "      <td>0.557</td>\n",
       "      <td>39.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.527</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>24.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Kobe Bryant</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>80</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>0.563</td>\n",
       "      <td>41.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0.450</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>35.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>75</td>\n",
       "      <td>48</td>\n",
       "      <td>27</td>\n",
       "      <td>0.640</td>\n",
       "      <td>38.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.495</td>\n",
       "      <td>...</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>27.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>Steve Nash</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>79</td>\n",
       "      <td>54</td>\n",
       "      <td>25</td>\n",
       "      <td>0.684</td>\n",
       "      <td>35.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>13.4</td>\n",
       "      <td>0.512</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>18.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Tim Duncan</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>0.763</td>\n",
       "      <td>34.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>14.8</td>\n",
       "      <td>0.484</td>\n",
       "      <td>...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>18.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Tony Parker</td>\n",
       "      <td>2005-06</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>0.763</td>\n",
       "      <td>33.9</td>\n",
       "      <td>7.8</td>\n",
       "      <td>14.2</td>\n",
       "      <td>0.548</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PLAYER_NAME GROUP_VALUE  GP   W   L  W_PCT   MIN   FGM   FGA  \\\n",
       "22       LeBron James     2005-06  79  47  32  0.595  42.5  11.1  23.1   \n",
       "24      Dirk Nowitzki     2005-06  81  60  21  0.741  38.1   9.3  19.3   \n",
       "35   Chauncey Billups     2005-06  81  64  17  0.790  36.1   5.2  12.5   \n",
       "57        Elton Brand     2005-06  79  44  35  0.557  39.2   9.6  18.2   \n",
       "61        Kobe Bryant     2005-06  80  45  35  0.563  41.0  12.2  27.2   \n",
       "70        Dwyane Wade     2005-06  75  48  27  0.640  38.6   9.3  18.8   \n",
       "117        Steve Nash     2005-06  79  54  25  0.684  35.4   6.8  13.4   \n",
       "131        Tim Duncan     2005-06  80  61  19  0.763  34.8   7.2  14.8   \n",
       "132       Tony Parker     2005-06  80  61  19  0.763  33.9   7.8  14.2   \n",
       "\n",
       "     FG_PCT  ...  TOV  STL  BLK  BLKA   PF   PTS  PLUS_MINUS  DD2  TD3  \\\n",
       "22    0.480  ...  3.3  1.6  0.8   0.8  2.3  31.4         3.5   21    5   \n",
       "24    0.480  ...  1.9  0.7  1.0   0.9  2.0  26.6         6.3   35    0   \n",
       "35    0.418  ...  2.1  0.9  0.1   0.7  2.0  18.5         7.3   27    0   \n",
       "57    0.527  ...  2.2  1.0  2.5   0.8  2.9  24.7         2.3   45    0   \n",
       "61    0.450  ...  3.1  1.8  0.4   1.0  2.9  35.4         4.0    4    0   \n",
       "70    0.495  ...  3.6  1.9  0.8   0.9  2.9  27.2         6.5   16    2   \n",
       "117   0.512  ...  3.5  0.8  0.2   0.4  1.5  18.8         6.0   43    1   \n",
       "131   0.484  ...  2.5  0.9  2.0   0.8  2.7  18.6         6.5   52    0   \n",
       "132   0.548  ...  3.1  1.0  0.1   1.0  2.0  18.9         6.4    8    0   \n",
       "\n",
       "     MVP_SHARES  \n",
       "22        0.550  \n",
       "24        0.435  \n",
       "35        0.344  \n",
       "57        0.040  \n",
       "61        0.386  \n",
       "70        0.070  \n",
       "117       0.739  \n",
       "131       0.026  \n",
       "132       0.007  \n",
       "\n",
       "[9 rows x 30 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][0].loc[train[0][0][\"MVP_SHARES\"] > 0.001]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s6ChjwAq6Ra"
   },
   "source": [
    "#### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "n2vnPsTR8_N1"
   },
   "outputs": [],
   "source": [
    "train_processed = []\n",
    "for fold in train:\n",
    "    fold_processed = []\n",
    "    for season in fold:\n",
    "        if \"PLAYER_NAME\" in season:\n",
    "            season = season.drop(columns = [\"PLAYER_NAME\", \"GROUP_VALUE\"])\n",
    "            \n",
    "        season.loc[:, season.columns != \"MVP_SHARES\"] =\\\n",
    "            season.loc[:, season.columns != \"MVP_SHARES\"]\\\n",
    "            .apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        fold_processed.append(season)\n",
    "    train_processed.append(fold_processed)\n",
    "\n",
    "val_processed = []\n",
    "for fold in val:\n",
    "    fold_processed = []\n",
    "    for season in fold:\n",
    "        if \"PLAYER_NAME\" in season:\n",
    "            season = season.drop(columns = [\"PLAYER_NAME\", \"GROUP_VALUE\"])\n",
    "            \n",
    "        season.loc[:, season.columns != \"MVP_SHARES\"] =\\\n",
    "            season.loc[:, season.columns != \"MVP_SHARES\"]\\\n",
    "            .apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "        fold_processed.append(season)\n",
    "    val_processed.append(fold_processed)\n",
    "\n",
    "\n",
    "test_processed = []\n",
    "for season in test:\n",
    "    if \"PLAYER_NAME\" in season:\n",
    "        season = season.drop(columns = [\"PLAYER_NAME\", \"GROUP_VALUE\"])\n",
    "        \n",
    "    season.loc[:, season.columns != \"MVP_SHARES\"] =\\\n",
    "        season.loc[:, season.columns != \"MVP_SHARES\"]\\\n",
    "        .apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "    test_processed.append(season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "i-7UvxNi8_N2",
    "outputId": "0b098403-214b-445d-c211-de8a1f49796b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GP</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W_PCT</th>\n",
       "      <th>MIN</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FG_PCT</th>\n",
       "      <th>FG3M</th>\n",
       "      <th>FG3A</th>\n",
       "      <th>...</th>\n",
       "      <th>TOV</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>BLKA</th>\n",
       "      <th>PF</th>\n",
       "      <th>PTS</th>\n",
       "      <th>PLUS_MINUS</th>\n",
       "      <th>DD2</th>\n",
       "      <th>TD3</th>\n",
       "      <th>MVP_SHARES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.627273</td>\n",
       "      <td>0.976834</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>0.803828</td>\n",
       "      <td>0.457014</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87500</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.856631</td>\n",
       "      <td>0.683453</td>\n",
       "      <td>0.338710</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.914894</td>\n",
       "      <td>0.159091</td>\n",
       "      <td>0.892727</td>\n",
       "      <td>0.806950</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.622010</td>\n",
       "      <td>0.457014</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43750</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.303030</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.684588</td>\n",
       "      <td>0.884892</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.971429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.729730</td>\n",
       "      <td>0.270833</td>\n",
       "      <td>0.296651</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.394265</td>\n",
       "      <td>0.956835</td>\n",
       "      <td>0.435484</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.558182</td>\n",
       "      <td>0.849421</td>\n",
       "      <td>0.729167</td>\n",
       "      <td>0.569378</td>\n",
       "      <td>0.669683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53125</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.616487</td>\n",
       "      <td>0.597122</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.595745</td>\n",
       "      <td>0.477273</td>\n",
       "      <td>0.569091</td>\n",
       "      <td>0.918919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.321267</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.719424</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.826255</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.598086</td>\n",
       "      <td>0.524887</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96875</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.706093</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.258065</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.789091</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.339713</td>\n",
       "      <td>0.601810</td>\n",
       "      <td>0.558824</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93750</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.405018</td>\n",
       "      <td>0.863309</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.932727</td>\n",
       "      <td>0.679537</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.406699</td>\n",
       "      <td>0.475113</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.899281</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>0.113636</td>\n",
       "      <td>0.932727</td>\n",
       "      <td>0.644788</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.377990</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.059524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81250</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.892086</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           GP         W         L     W_PCT       MIN       FGM       FGA  \\\n",
       "22   0.914286  0.638298  0.409091  0.627273  0.976834  0.885417  0.803828   \n",
       "24   0.971429  0.914894  0.159091  0.892727  0.806950  0.697917  0.622010   \n",
       "35   0.971429  1.000000  0.068182  0.981818  0.729730  0.270833  0.296651   \n",
       "57   0.914286  0.574468  0.477273  0.558182  0.849421  0.729167  0.569378   \n",
       "61   0.942857  0.595745  0.477273  0.569091  0.918919  1.000000  1.000000   \n",
       "70   0.800000  0.659574  0.295455  0.709091  0.826255  0.697917  0.598086   \n",
       "117  0.914286  0.787234  0.250000  0.789091  0.702703  0.437500  0.339713   \n",
       "131  0.942857  0.936170  0.113636  0.932727  0.679537  0.479167  0.406699   \n",
       "132  0.942857  0.936170  0.113636  0.932727  0.644788  0.541667  0.377990   \n",
       "\n",
       "       FG_PCT      FG3M      FG3A  ...      TOV       STL       BLK      BLKA  \\\n",
       "22   0.457014  0.470588  0.571429  ...  0.87500  0.608696  0.242424  0.461538   \n",
       "24   0.457014  0.411765  0.392857  ...  0.43750  0.217391  0.303030  0.538462   \n",
       "35   0.176471  0.676471  0.619048  ...  0.50000  0.304348  0.030303  0.384615   \n",
       "57   0.669683  0.000000  0.000000  ...  0.53125  0.347826  0.757576  0.461538   \n",
       "61   0.321267  0.676471  0.773810  ...  0.81250  0.695652  0.121212  0.615385   \n",
       "70   0.524887  0.058824  0.119048  ...  0.96875  0.739130  0.242424  0.538462   \n",
       "117  0.601810  0.558824  0.511905  ...  0.93750  0.260870  0.060606  0.153846   \n",
       "131  0.475113  0.000000  0.011905  ...  0.62500  0.304348  0.606061  0.461538   \n",
       "132  0.764706  0.029412  0.059524  ...  0.81250  0.347826  0.030303  0.615385   \n",
       "\n",
       "           PF       PTS  PLUS_MINUS       DD2    TD3  MVP_SHARES  \n",
       "22   0.392857  0.856631    0.683453  0.338710  0.625       0.550  \n",
       "24   0.285714  0.684588    0.884892  0.564516  0.000       0.435  \n",
       "35   0.285714  0.394265    0.956835  0.435484  0.000       0.344  \n",
       "57   0.607143  0.616487    0.597122  0.725806  0.000       0.040  \n",
       "61   0.607143  1.000000    0.719424  0.064516  0.000       0.386  \n",
       "70   0.607143  0.706093    0.899281  0.258065  0.250       0.070  \n",
       "117  0.107143  0.405018    0.863309  0.693548  0.125       0.739  \n",
       "131  0.535714  0.397849    0.899281  0.838710  0.000       0.026  \n",
       "132  0.285714  0.408602    0.892086  0.129032  0.000       0.007  \n",
       "\n",
       "[9 rows x 28 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_processed[0][0].loc[train_processed[0][0][\"MVP_SHARES\"] > 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mwcF3R_FTxly",
    "outputId": "801684e3-3dd0-4d35-d5b0-7bf5a68d39c8"
   },
   "outputs": [],
   "source": [
    "for fold in train_processed:\n",
    "    for season in fold:\n",
    "        if season.isnull().values.any():\n",
    "            print(season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCN5lVmm17K6"
   },
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "WZVjCtIYq6Rk",
    "outputId": "00263bfc-2774-479d-b012-113e64acee09"
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class MVPDataset(Dataset):\n",
    "    def __init__(self, samples):\n",
    "        all_samples = pd.concat(samples)\n",
    "        all_votes = all_samples.loc[all_samples['MVP_SHARES'] > 0.001]\n",
    "        self.samples = all_votes.loc[:, :'MVP_SHARES']\n",
    "        self.labels = all_votes.loc[:,'MVP_SHARES']\n",
    "        self.n_samples = len(self.samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = torch.tensor(self.samples.iloc[index].values, dtype=torch.float)\n",
    "        label = torch.tensor(self.labels.iloc[index], dtype=torch.float)\n",
    "        return data, label\n",
    "\n",
    "\n",
    "train_datasets = []\n",
    "for i in range(num_folds):\n",
    "    trainingDataset = MVPDataset(train_processed[i])\n",
    "    train_datasets.append(trainingDataset)\n",
    "    \n",
    "val_datasets = []\n",
    "for i in range(num_folds):\n",
    "    validationDataset = MVPDataset(val_processed[i])\n",
    "    val_datasets.append(validationDataset)\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, inputSize):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear1 = nn.Linear(inputSize, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(32, 64)\n",
    "        self.linear3 = nn.Linear(64,1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        x = self.relu(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "rs3y4XNcTf9E",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------ Fold 0 ------------------\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.07745991423726081 \tMax: 0.1686161309480667\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.05078512597829103 \tMax: 0.09772029519081116\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.02793507035821676 \tMax: 0.05962264537811279\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.012253835750743746 \tMax: 0.017316380515694618\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.006719907186925412 \tMax: 0.011348898522555828\n",
      "\n",
      "------------------ Fold 1 ------------------\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.0056119348853826525 \tMax: 0.007930330000817776\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.0035553960595279934 \tMax: 0.0048447661101818085\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.0025585934752598407 \tMax: 0.003496559802442789\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.002009152458049357 \tMax: 0.0036359236110001802\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.0014209324261173605 \tMax: 0.0021988344378769398\n",
      "\n",
      "------------------ Fold 2 ------------------\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.0010069683970262606 \tMax: 0.0015252665616571903\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.00081682730686023 \tMax: 0.0015707064885646105\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.0006423045350756082 \tMax: 0.0012498494470492005\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.0005186347827677511 \tMax: 0.0007004875806160271\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.00042370214618535503 \tMax: 0.0006070688832551241\n",
      "\n",
      "------------------ Fold 3 ------------------\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.00034877125872299073 \tMax: 0.00046522292541339993\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.0003516735319863074 \tMax: 0.0007816076395101845\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.0002355682707275264 \tMax: 0.0003674138570204377\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.0001898873408208601 \tMax: 0.00033770661684684455\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "..........\n",
      "Avg: 0.00017305350338574498 \tMax: 0.00025920136249624193\n",
      "\n",
      "------------------ Fold 4 ------------------\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.00015372570325982652 \tMax: 0.00021361830295063555\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.00012242211838990139 \tMax: 0.00021231504797469825\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 0.00010549717585996 \tMax: 0.00017938201199285686\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 8.862507658907109e-05 \tMax: 0.00019823526963591576\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      ".........\n",
      "Avg: 7.551646841521788e-05 \tMax: 9.792726632440463e-05\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "num_epochs = 100\n",
    "\n",
    "model = NeuralNetwork(28)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "lossfn = nn.MSELoss()\n",
    "\n",
    "for i in range(num_folds):\n",
    "    print(f\"\\n------------------ Fold {i} ------------------\")\n",
    "    train_dl = DataLoader(train_datasets[i], batch_size=20, shuffle=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = []\n",
    "        for X, y in train_dl:\n",
    "            if torch.any(torch.isnan(X)).item():\n",
    "                print(X)\n",
    "                raise Exception\n",
    "            pred = model(X).flatten()\n",
    "            loss = lossfn(pred, y)\n",
    "            epoch_loss.append(loss.item())\n",
    "            print(\".\", end=\"\")\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        loss_hist.extend(epoch_loss)\n",
    "        mean = np.mean(epoch_loss)\n",
    "        e_max = max(epoch_loss)\n",
    "        if epoch % 20 == 19:\n",
    "            print(f\"\\nAvg: {mean} \\tMax: {e_max}\")\n",
    "        else:\n",
    "            print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "NBA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
